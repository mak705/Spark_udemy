from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('Basics').getOrCreate()
df.show()
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+

df.printSchema()
root
 |-- age: long (nullable = true)
 |-- name: string (nullable = true)

df.columns
DataFrame[summary: string, age: string, name: string]

df.describe().show()
|summary|               age|   name|
+-------+------------------+-------+
|  count|                 2|      3|
|   mean|              24.5|   null|
| stddev|7.7781745930520225|   null|
|    min|                19|   Andy|
|    max|                30|Michael|

from pyspark.sql.types import (StructField, StringType,
                               IntegerType,StructType)
####How to change the scema
data_schema = [StructField('age', IntegerType(),True),
               StructField('name',IntegerType(),True)]

final_struct = StructType(fields=data_schema)

df = spark.read.json('/home/mak/spark_udemy/1.Python-and-Spark-for-Big-Data-master/2.Spark_DataFrames/people.json'
                    ,schema=final_struct)

df.printSchema()
root
 |-- age: integer (nullable = true)
 |-- name: integer (nullable = true)

